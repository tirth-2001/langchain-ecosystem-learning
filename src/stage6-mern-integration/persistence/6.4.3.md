## ðŸ§© Stage 6.4.3 â€” Controller Integration Plan

### ðŸŽ¯ Goal

Persist:

- Each **chat message** (user + assistant)
- **Session context** (so you can reload conversations)
- Maintain **memory continuity** beyond server restarts

---

## ðŸ”§ Step 1 â€” Create Chat Service (for DB persistence)

Create a new file:
`src/services/chatService.ts`

```ts
import ChatSession from '../models/chatSession.model.js'
import ChatMessage from '../models/chatMessage.model.js'

/**
 * Find or create a chat session.
 */
export const findOrCreateSession = async (sessionId: string, userId?: string) => {
  let session = await ChatSession.findOne({ sessionId })
  if (!session) {
    session = await ChatSession.create({
      sessionId,
      userId: userId || 'anonymous',
      title: 'New Chat',
      lastMessageAt: new Date(),
    })
  }
  return session
}

/**
 * Save a message to MongoDB.
 */
export const saveMessage = async (sessionId: string, role: 'human' | 'ai', content: string) => {
  await ChatMessage.create({
    sessionId,
    role,
    content,
    timestamp: new Date(),
  })

  await ChatSession.updateOne({ sessionId }, { lastMessageAt: new Date(), $inc: { messageCount: 1 } })
}

/**
 * Get previous messages for memory hydration.
 */
export const getSessionMessages = async (sessionId: string) => {
  return ChatMessage.find({ sessionId }).sort({ timestamp: 1 }).lean()
}
```

---

## âš™ï¸ Step 2 â€” Update `chatAgentExecutor.ts` for Persistent Memory

Weâ€™ll modify your `getMessageHistory` to hydrate from MongoDB.

```ts
// chatAgentExecutor.ts
import { ChatMessageHistory } from 'langchain/memory'
import { getSessionMessages } from '../services/chatService.js'

// inside RunnableWithMessageHistory config:
getMessageHistory: async (sessionId) => {
  const history = new ChatMessageHistory()
  const messages = await getSessionMessages(sessionId)

  for (const msg of messages) {
    if (msg.role === 'human') {
      history.addUserMessage(msg.content)
    } else {
      history.addAIChatMessage(msg.content)
    }
  }

  return history
},
```

This means: when a user reconnects, we reload their past messages into the LangChain memory automatically.

---

## ðŸ§  Step 3 â€” Update Controller (`askControllerV2`)

Now weâ€™ll wire persistence inside your existing streaming loop.

### âœ… Updated `askControllerV2`

```ts
import { findOrCreateSession, saveMessage } from '../services/chatService.js'

export const askControllerV2 = async (req: Request, res: Response) => {
  const { query, sessionId = 'user-123', userId } = req.body

  if (!query) {
    return res.status(400).json({ error: "Missing 'query' field in body" })
  }

  try {
    // Find or create session
    await findOrCreateSession(sessionId, userId)

    // Save user message
    await saveMessage(sessionId, 'human', query)

    // Initialize agent executor
    const executor = await chatAgentExecutor()

    res.setHeader('Content-Type', 'text/event-stream')
    res.setHeader('Cache-Control', 'no-cache')
    res.setHeader('Connection', 'keep-alive')

    let finalOutput = ''

    const stream = await executor.streamEvents(
      { input: query },
      {
        configurable: { sessionId },
        version: 'v2',
      },
    )

    for await (const event of stream) {
      if (event.event === 'on_chat_model_stream') {
        const content = event.data?.chunk?.content
        if (content && typeof content === 'string') {
          finalOutput += content
          res.write(`data: ${JSON.stringify({ chunk: content })}\n\n`)
        }
      }

      if (event.event === 'on_tool_start') {
        res.write(`data: ${JSON.stringify({ type: 'tool_start', tool: event.name })}\n\n`)
      }

      if (event.event === 'on_tool_end') {
        res.write(
          `data: ${JSON.stringify({
            type: 'tool_end',
            tool: event.name,
            output: event.data?.output,
          })}\n\n`,
        )
      }

      if (event.event === 'on_chain_end' && event.name === 'AgentExecutor') {
        const output = event.data?.output?.output
        if (output && typeof output === 'string') {
          finalOutput = output
          res.write(`data: ${JSON.stringify({ chunk: output })}\n\n`)
        }
      }
    }

    // Persist assistant message
    if (finalOutput) {
      await saveMessage(sessionId, 'ai', finalOutput)
    }

    res.write(`event: end\ndata: {}\n\n`)
    res.end()
  } catch (err: any) {
    console.error('Error in /api/ask:', err.message)
    res.write(`event: error\ndata: ${JSON.stringify({ error: err.message })}\n\n`)
    res.end()
  }
}
```

---

## ðŸ’¾ Step 4 â€” End-to-End Flow Recap

**What happens now:**

1. Request comes with `query` + `sessionId`.
2. Controller creates/finds session.
3. User message â†’ saved in Mongo.
4. LangChain loads previous history from DB.
5. Model streams response as usual.
6. Final assistant message â†’ saved in Mongo.
7. Chat session now persistent forever âœ…

---

## ðŸ§  Step 5 â€” Next Steps (Optional Enhancements)

| Enhancement           | Description                                               |
| --------------------- | --------------------------------------------------------- |
| ðŸ”„ Session Management | Add `/api/sessions` route to list or resume past sessions |
| ðŸ§© Context Tagging    | Add `context` field to messages to separate topic threads |
| ðŸ“œ Token Count        | Store token usage per message (for cost tracking)         |
| âš¡ Caching            | Use Redis for temporary memory before DB write            |

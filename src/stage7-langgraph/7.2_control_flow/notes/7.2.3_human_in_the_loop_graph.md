# âœ… **7.2.3 â€” Human-in-the-Loop Pause Node (HITL Checkpoint)**

## ğŸ¯ **Goal**

Create a LangGraph flow that:

1. Processes input
2. Hits a special node (`humanNode`) that **pauses execution**
3. Waits for external human response
4. Resumes the graph with the new human input
5. Continues to final output

This gives you:

âœ… â€œApprovalâ€ step
âœ… â€œAsk human for clarificationâ€
âœ… â€œNeed more detailsâ€ step
âœ… Interruption / checkpoint
âœ… External interaction support

---

# âœ… **The Core Idea (Very Important)**

LangGraph lets you pause execution by returning:

```ts
return new AwaitResponse({ ...payload })
```

This tells LangGraph:

> "Stop the graph now. Return control to the caller.
> When the caller provides more input â†’ resume from here."

---

# âœ… **Architecture of HITL Graph**

```
User Input
   â†“
AI Draft Node
   â†“
HITL Pause Node  â†â”€â”€ Human must approve or modify
   â†“ (resume)
AI Finalize Node
   â†“
END
```

---

# âœ… **1. Define State**

We track:

- input
- draft output (AI-generated)
- human feedback
- final output

```ts
import { Annotation, StateGraph, END } from '@langchain/langgraph'
import { AwaitResponse } from '@langchain/langgraph/web'
import { ChatOpenAI } from '@langchain/openai'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { RunnableSequence } from '@langchain/core/runnables'

const StateAnnotation = Annotation.Root({
  input: Annotation<string>(),
  draft: Annotation<string>(),
  humanFeedback: Annotation<string>(),
  final: Annotation<string>(),
})
```

---

# âœ… **2. AI Draft Node â€” creates first output**

```ts
const draftPrompt = ChatPromptTemplate.fromTemplate(`
Create a draft response for the userâ€™s input:
"{input}"
`)

const draftChain = RunnableSequence.from([
  draftPrompt,
  new ChatOpenAI({ modelName: 'gpt-4o-mini' }),
  (out) => out.content.trim(),
])

async function draftNode(state: typeof StateAnnotation.State) {
  const draft = await draftChain.invoke({ input: state.input })
  return { draft }
}
```

---

# âœ… **3. Human-in-the-loop Pause Node**

This is the magic.
Instead of returning a normal state update, we return:

```ts
return new AwaitResponse({ draft })
```

This pauses the graph.

```ts
async function humanApprovalNode(state: typeof StateAnnotation.State) {
  return new AwaitResponse({
    message: 'âœ… Please review the AI-generated draft',
    draft: state.draft,
  })
}
```

Meaning:

- LangGraph execution **stops here**
- The client receives `{ draft, message }`
- The client must send `humanFeedback`
- The graph then resumes on the next node

---

# âœ… **4. Finalize Node â€” completes with human feedback**

```ts
const finalizePrompt = ChatPromptTemplate.fromTemplate(`
User input: {input}
Draft: {draft}
Human feedback: {humanFeedback}

Produce a polished final answer incorporating the feedback.
`)

const finalizeChain = RunnableSequence.from([
  finalizePrompt,
  new ChatOpenAI({ modelName: 'gpt-4o-mini' }),
  (out) => out.content.trim(),
])

async function finalizeNode(state: typeof StateAnnotation.State) {
  const final = await finalizeChain.invoke({
    input: state.input,
    draft: state.draft,
    humanFeedback: state.humanFeedback,
  })
  return { final }
}
```

---

# âœ… **5. Build Graph**

```ts
const workflow = new StateGraph(StateAnnotation)
  .addNode('draft', draftNode)
  .addNode('approval', humanApprovalNode)
  .addNode('final', finalizeNode)
  .addEdge('__start__', 'draft')
  .addEdge('draft', 'approval')
  .addEdge('approval', 'final')
  .addEdge('final', END)

const app = workflow.compile()
```

---

# âœ… **6. HOW TO RUN THE HITL GRAPH**

### âœ… Step 1: First invoke (no human input yet)

```ts
const step1 = await app.invoke({ input: 'Write a thank you email.' })
console.log(step1)
// â†’ { draft: "...", message: "Please review the draft" }
```

The graph **pauses** here.

The frontend should now:

âœ… Show draft
âœ… Ask user: "Approve or modify?"
âœ… Gather human feedback

---

### âœ… Step 2: Resume graph with human feedback

```ts
const step2 = await app.invoke({
  input: 'Write a thank you email.',
  humanFeedback: 'Make it shorter and more casual',
})
console.log(step2)
// â†’ { final: "..." }
```

The graph resumes at `"final"` node and completes.

---

# âœ… **Thatâ€™s HITL!**

This is EXACTLY how professional systems work:

âœ… ChatGPT â€œApprove Tool Callâ€
âœ… Claude â€œShould I proceed?â€
âœ… Slack agents requesting confirmation

You have now built:
âœ” Pausable graph
âœ” Human feedback injection
âœ” Resume logic
âœ” State-aware workflow

---

# âœ… **7.2.3 Complete âœ…**

This unlocks the next systems:

- Agent review & approval steps
- Legal/document review flows
- Developer agent compile â†’ human fix â†’ re-run cycles
- Multi-agent collaboration workflows

# âš™ï¸ **7.2.1 â€” Conditional Classifier Node (LLM-Based Routing)**

---

## ğŸ¯ **Goal**

Design a **LangGraph flow that can decide its next node** dynamically â€” based on LLM classification.

Example flow:

```
User Input â†’ Classifier â†’ (Search Node | Response Node)
```

The **Classifier Node** inspects the userâ€™s input and routes it to:

- ğŸ” `search` node â†’ if user asks for external info
- ğŸ’¬ `respond` node â†’ if LLM can answer directly

This pattern is the foundation for **ReAct**, **CrewAI-style** branching, and **retrieval orchestration** in real-world agentic pipelines.

---

## ğŸ§© **Concept Recap**

LangGraph allows **conditional edges** that depend on **state** or **LLM output**.

```ts
.addConditionalEdges("classifier", (state) => {
  if (state.route === "search") return "search";
  return "respond";
})
```

- You can compute `state.route` dynamically using an LLM classifier node.
- The graph then picks the next path automatically.

---

## ğŸ§  **Architecture Overview**

```plaintext
[__start__]
   â†“
[classifier]
   â”œâ”€â”€ route = "search" â†’ [searchNode]
   â””â”€â”€ route = "respond" â†’ [respondNode]
                 â†“
                [END]
```

---

## ğŸ’» **Implementation â€” `conditionalClassifierGraph.ts`**

```ts
import { StateGraph, Annotation, END } from '@langchain/langgraph'
import { ChatOpenAI } from '@langchain/openai'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { RunnableSequence } from '@langchain/core/runnables'
import 'dotenv/config'

/**
 * 1ï¸âƒ£ Define State
 */
const StateAnnotation = Annotation.Root({
  query: Annotation<string>({ reducer: (_curr, next) => next }),
  route: Annotation<string>({ reducer: (_curr, next) => next }),
  answer: Annotation<string>({ reducer: (_curr, next) => next }),
})

/**
 * 2ï¸âƒ£ Define Model
 */
const model = new ChatOpenAI({
  modelName: 'gpt-4o-mini',
  temperature: 0,
})

/**
 * 3ï¸âƒ£ Classifier Node
 */
const classifierPrompt = ChatPromptTemplate.fromTemplate(`
You are a routing assistant.
Classify the user's request into one of the following types:
- "search" if the question needs external or factual lookup
- "respond" if it can be answered directly from general knowledge.

User query: {query}

Reply only with one word: search or respond.
`)

const classifierChain = RunnableSequence.from([
  classifierPrompt,
  model,
  (output) => output.content.trim().toLowerCase(),
])

async function classifierNode(state: typeof StateAnnotation.State) {
  const route = await classifierChain.invoke({ query: state.query })
  console.log('ğŸ§­ Classifier route:', route)
  return { route }
}

/**
 * 4ï¸âƒ£ Search Node
 */
async function searchNode(state: typeof StateAnnotation.State) {
  console.log('ğŸ” Performing pseudo-search...')
  const fakeSearchResult = `Search result: Latest info for "${state.query}".`
  return { answer: fakeSearchResult }
}

/**
 * 5ï¸âƒ£ Respond Node
 */
const responsePrompt = ChatPromptTemplate.fromTemplate(`
Answer the user's question concisely:
{query}
`)

const responseChain = RunnableSequence.from([responsePrompt, model, (output) => output.content.trim()])

async function respondNode(state: typeof StateAnnotation.State) {
  const response = await responseChain.invoke({ query: state.query })
  return { answer: response }
}

/**
 * 6ï¸âƒ£ Build Graph with Conditional Edge
 */
const workflow = new StateGraph(StateAnnotation)
  .addNode('classifier', classifierNode)
  .addNode('search', searchNode)
  .addNode('respond', respondNode)
  .addEdge('__start__', 'classifier')
  .addConditionalEdges(
    'classifier',
    (state) => {
      if (state.route === 'search') return 'search'
      return 'respond'
    },
    {
      search: 'search',
      respond: 'respond',
    },
  )
  .addEdge('search', END)
  .addEdge('respond', END)

const app = workflow.compile()

/**
 * 7ï¸âƒ£ Run Example
 */
async function main() {
  console.log('ğŸ§© Conditional Routing Graph Demo\n')

  const testQueries = ['What is the capital of New Zealand?', 'Tell me a motivational quote.']

  for (const query of testQueries) {
    console.log('='.repeat(60))
    console.log('ğŸ“ Query:', query)
    const result = await app.invoke({ query })
    console.log('âœ… Final Output:', result)
  }
}

main()
```

---

## ğŸ§¾ **Expected Console Output**

```
ğŸ§© Conditional Routing Graph Demo
============================================================
ğŸ“ Query: What is the capital of New Zealand?
ğŸ§­ Classifier route: search
ğŸ” Performing pseudo-search...
âœ… Final Output: {
  query: 'What is the capital of New Zealand?',
  route: 'search',
  answer: 'Search result: Latest info for "What is the capital of New Zealand?"'
}

============================================================
ğŸ“ Query: Tell me a motivational quote.
ğŸ§­ Classifier route: respond
âœ… Final Output: {
  query: 'Tell me a motivational quote.',
  route: 'respond',
  answer: 'Believe in yourself â€” every expert was once a beginner.'
}
```

---

## ğŸ§  **Key Learnings**

| Concept                  | Explanation                                                                                     |
| ------------------------ | ----------------------------------------------------------------------------------------------- |
| **Conditional Edges**    | Allow dynamic flow control based on runtime state.                                              |
| **LLM Routing**          | Classifier LLM determines next node (`route`).                                                  |
| **Determinism**          | The graph orchestrator remains deterministic â€” even though the route decision is probabilistic. |
| **Extensibility**        | You can expand routes easily (e.g., `analyze`, `summarize`, `search`, `respond`).               |
| **Hybrid Agent Pattern** | Combines symbolic control (LangGraph) + neural reasoning (LLM) â€” core of modern agents.         |

---

## ğŸ§© **Next Steps**

In the next sub-stage, **7.2.2 â€“ Retry Node**, weâ€™ll make the graph **resilient**:

- Automatically retry failed nodes
- Add exponential backoff
- Add fallback routes (`on_error â†’ alternate node`)

This ensures your graph can **recover gracefully** â€” just like a production-grade AI system.

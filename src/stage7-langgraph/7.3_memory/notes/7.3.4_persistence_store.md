# ‚úÖ **7.3.4 ‚Äî Persistent Store (Redis / Mongo / File Checkpointer)**

---

## ü•Ö **1. GOAL**

Add a **persistent checkpoint store** to your LangGraph app so that:

- ‚úÖ The graph can **pause and resume** even after restarts
- ‚úÖ Memory and state are **stored externally** (not in-memory)
- ‚úÖ It supports **multi-session**, **multi-user** context recall
- ‚úÖ Lays foundation for **long-lived conversational agents**

---

### üí° **End Output**

> A graph that remembers ‚Äî even after the process restarts.

You‚Äôll be able to run:

```bash
node graph-persistent-store.js
```

‚Üí pause midway, restart app, run again
‚Üí graph continues exactly where it left off.

---

## üß† **2. THEORY**

---

### üìò 2.1 What is a Checkpointer?

LangGraph uses the concept of a **checkpointer** to persist graph state.
Think of it like **‚Äúsave game‚Äù checkpoints** in a workflow.

A checkpointer stores:

- Current node name
- Current state values
- Execution history
- Thread/session metadata

---

### üìò 2.2 Built-in Options

| Checkpointer  | Description                                         |
| ------------- | --------------------------------------------------- |
| `MemorySaver` | In-memory (temporary, not persistent)               |
| `SqliteSaver` | Lightweight local DB (default in LangGraph dev)     |
| `RedisSaver`  | Scalable distributed store                          |
| `MongoSaver`  | Persistent store for multi-user apps                |
| Custom        | Implement `ICheckpointer` interface for your own DB |

---

### üìò 2.3 How It Works

Each time the graph runs:

1. It saves the updated state in the checkpointer
2. On next run with the same `thread_id`,
   LangGraph loads that checkpoint automatically.

‚Üí Result: seamless resume and continuous memory.

---

### üìò 2.4 Minimal Flow Example

```
Input (user1)
  ‚Üì
Graph executes nodes...
  ‚Üì
Checkpoint saved in Mongo
  ‚Üì
App restarts ‚Üí same thread_id
  ‚Üì
Graph resumes from last saved node
```

---

## ‚öôÔ∏è **3. CODE SNIPPETS (Step-by-Step)**

---

### ‚úÖ 3.1 State Definition

We'll use a simple conversational state with summary and history.

```ts
const StateAnnotation = Annotation.Root({
  input: Annotation<string>(),
  summary: Annotation<string>(),
  chatHistory: Annotation<string[]>({
    reducer: (curr, next) => [...(curr ?? []), ...(next ?? [])],
  }),
  response: Annotation<string>(),
})
```

---

### ‚úÖ 3.2 Create Persistent Checkpointer

You can pick one:

- **Redis:** best for production, multi-session agents
- **MongoDB:** works with your MERN setup
- **File-based:** good for local experiments

We‚Äôll demo Mongo and File both.

#### (a) MongoSaver Example

```ts
import { MongoSaver } from '@langchain/langgraph'
import mongoose from 'mongoose'

await mongoose.connect(process.env.MONGO_URI || 'mongodb://localhost:27017/langgraph')

const checkpointer = new MongoSaver({
  collectionName: 'graph_checkpoints',
  client: mongoose.connection.getClient(),
})
```

#### (b) File Checkpointer (simpler alternative)

```ts
import { FileSaver } from '@langchain/langgraph'
import path from 'path'

const checkpointer = new FileSaver({
  dir: path.join(process.cwd(), 'checkpoints'),
})
```

---

### ‚úÖ 3.3 Example Graph

We‚Äôll reuse the memory+LLM graph from before.

```ts
async function memoryInputNode(state) {
  return { chatHistory: [`Human: ${state.input}`] }
}

async function llmNode(state) {
  const response = `Replying to: ${state.input}`
  return { response }
}

async function memoryOutputNode(state) {
  return { chatHistory: [`AI: ${state.response}`] }
}
```

---

### ‚úÖ 3.4 Build Graph with Persistent Checkpointer

```ts
const graph = new StateGraph(StateAnnotation)
  .addNode('memoryInput', memoryInputNode)
  .addNode('llm', llmNode)
  .addNode('memoryOutput', memoryOutputNode)
  .addEdge(START, 'memoryInput')
  .addEdge('memoryInput', 'llm')
  .addEdge('llm', 'memoryOutput')
  .addEdge('memoryOutput', END)

const app = graph.compile({
  checkpointer, // <‚Äî Mongo or FileSaver
})
```

---

### ‚úÖ 3.5 Run with Thread ID (Persistence Enabled)

```ts
const threadId = 'session-user-42'
const config = { configurable: { thread_id: threadId } }

let result = await app.invoke({ input: 'Hello!' }, config)
console.log('Response:', result.response)

result = await app.invoke({ input: 'What did I say earlier?' }, config)
console.log('Response:', result.response)
```

---

# üíª **4. FINAL FILE (Plug-and-Play Code)**

üìÑ `graph-persistent-store.ts`

```ts
import { Annotation, StateGraph, START, END } from '@langchain/langgraph'
import { FileSaver } from '@langchain/langgraph'
import path from 'path'
import 'dotenv/config'

/**
 * 1Ô∏è‚É£ State Definition
 */
const StateAnnotation = Annotation.Root({
  input: Annotation<string>(),
  chatHistory: Annotation<string[]>({
    reducer: (curr, next) => [...(curr ?? []), ...(next ?? [])],
  }),
  response: Annotation<string>(),
})

/**
 * 2Ô∏è‚É£ File-based Checkpointer
 */
const checkpointer = new FileSaver({
  dir: path.join(process.cwd(), 'checkpoints'),
})

/**
 * 3Ô∏è‚É£ Simple Nodes
 */
async function memoryInputNode(state: typeof StateAnnotation.State) {
  console.log('üß† Adding input to chat history...')
  return { chatHistory: [`Human: ${state.input}`] }
}

async function llmNode(state: typeof StateAnnotation.State) {
  console.log('üí¨ Simulating LLM response...')
  const history = (state.chatHistory ?? []).join('\n')
  const response = `You said: "${state.input}". Previously: [${history}]`
  return { response }
}

async function memoryOutputNode(state: typeof StateAnnotation.State) {
  console.log('üß† Storing LLM reply...')
  return { chatHistory: [`AI: ${state.response}`] }
}

/**
 * 4Ô∏è‚É£ Build Graph
 */
const graph = new StateGraph(StateAnnotation)
  .addNode('memoryInput', memoryInputNode)
  .addNode('llm', llmNode)
  .addNode('memoryOutput', memoryOutputNode)
  .addEdge(START, 'memoryInput')
  .addEdge('memoryInput', 'llm')
  .addEdge('llm', 'memoryOutput')
  .addEdge('memoryOutput', END)

const app = graph.compile({
  checkpointer,
})

/**
 * 5Ô∏è‚É£ Run Demo
 */
async function main() {
  console.log('\n=== 7.3.4 ‚Äî Persistent Store Graph ===\n')

  const threadId = 'demo-thread-42'
  const config = { configurable: { thread_id: threadId } }

  // Run 1
  console.log('üë§ User: Hello!')
  const step1 = await app.invoke({ input: 'Hello!' }, config)
  console.log('ü§ñ:', step1.response)

  // Simulate restart ‚Üí Run again
  console.log('\nüîÅ Simulating resume (same thread)...\n')
  const step2 = await app.invoke({ input: 'What did I say before?' }, config)
  console.log('ü§ñ:', step2.response)
}

main().catch(console.error)
```

---

# üí° **5. NOTES & TIPS**

| Concept                   | Explanation                                               |
| ------------------------- | --------------------------------------------------------- |
| **Thread ID**             | Used to link graph sessions to stored checkpoints         |
| **Checkpoint Store**      | Handles state persistence and resume logic                |
| **Memory vs. Checkpoint** | Memory lives in state; checkpoints persist state          |
| **Production Tip**        | Use Redis or MongoSaver in multi-user agents              |
| **Recovery Flow**         | When a node crashes, you can resume from last checkpoint  |
| **Inspect Checkpoints**   | Each checkpoint is JSON; you can view full state snapshot |

---

## ‚úÖ **You Now Have**

‚úîÔ∏è Full RAG Graph with persistent memory
‚úîÔ∏è Ability to pause/resume or recover
‚úîÔ∏è Support for multi-session, multi-user workflows

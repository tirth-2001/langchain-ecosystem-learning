# üß© 7.4.2 ‚Äî Web Tool Node (HTTP Fetch Tool)

---

## 1Ô∏è‚É£ Goal

Create a **Web Tool Node** inside LangGraph that:

‚úî Accepts user input (e.g., `‚Äúweather in London‚Äù`)
‚úî Calls an **external API** (e.g., `https://api.weatherapi.com` or mock)
‚úî Stores the returned structured result in graph state
‚úî Uses LLM to generate a **clean natural language formatted output**

Flow:

```
User Input (e.g., "weather in Tokyo")
      ‚Üì
[extractLocationNode]   ‚Üê optional LLM helper
      ‚Üì
[weatherToolNode]        ‚Üê real HTTP API call
      ‚Üì
[weatherAnswerNode]      ‚Üê final LLM formatter
      ‚Üì
END
```

---

## 2Ô∏è‚É£ Theory & Concepts

### üîπ 2.1 What makes a ‚ÄúWeb Tool Node‚Äù?

A **Web Tool Node** is simply:

- a graph node that performs **non-LLM external computation**
- using HTTP, DB queries, SDKs, cloud APIs, etc.
- that stores results in `state` so later nodes can use them

### üîπ 2.2 When to use Web Tools?

Use web tools when you need:

| Scenario                | LLM good? | Tool needed? |
| ----------------------- | --------- | ------------ |
| factual lookup          | üö´        | ‚úÖ           |
| real-time data          | üö´        | ‚úÖ           |
| private enterprise data | üö´        | ‚úÖ           |
| parsing JSON API        | ‚ùå        | ‚úîÔ∏è           |

### üîπ 2.3 Node order

We separate concerns into multiple nodes:

| Node                | Responsibility                    |
| ------------------- | --------------------------------- |
| extractLocationNode | optional: LLM parse the location  |
| weatherToolNode     | fetch weather JSON                |
| weatherAnswerNode   | convert result ‚Üí natural language |

---

## 3Ô∏è‚É£ Code Snippets (Step-by-Step)

> We‚Äôll keep the HTTP API **free + no-key**, using a mock or public endpoint.

### üèó 3.1 State Definition

```ts
import { Annotation } from '@langchain/langgraph'

const StateAnnotation = Annotation.Root({
  input: Annotation<string>(),
  location: Annotation<string>({ reducer: (_, u) => u ?? _ }),
  weatherJson: Annotation<any>({ reducer: (_, u) => u ?? _ }),
  answer: Annotation<string>({ reducer: (_, u) => u ?? _ }),
})
```

---

### üîç 3.2 Extract Location Node (LLM assisted)

```ts
import { ChatOpenAI } from '@langchain/openai'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { RunnableSequence } from '@langchain/core/runnables'

const model = new ChatOpenAI({ modelName: 'gpt-4o-mini', temperature: 0 })

const extractLocationPrompt = ChatPromptTemplate.fromTemplate(`
Extract and return ONLY the location from the user message:
"{input}"

Examples:
- "weather in London" ‚Üí "London"
- "tell me weather at New York" ‚Üí "New York"
- "how is temperature in Tokyo today" ‚Üí "Tokyo"
Return only the location, without other text.
`)

const extractLocationChain = RunnableSequence.from([extractLocationPrompt, model, (out) => out.content.trim()])

async function extractLocationNode(state: typeof StateAnnotation.State) {
  console.log('üìç Parsing location via LLM...')
  const location = await extractLocationChain.invoke({ input: state.input })
  return { location }
}
```

---

### üå¶ 3.3 Weather Tool Node (HTTP API request)

You may use a real weather API, but for reproducibility we will use:

> `https://wttr.in/<city>?format=j1`

Example: `https://wttr.in/Tokyo?format=j1`

```ts
import fetch from 'node-fetch' // if using Node < 18

async function weatherToolNode(state: typeof StateAnnotation.State) {
  console.log('üå¶ Fetching weather for:', state.location)

  if (!state.location) return { weatherJson: { error: 'Missing location' } }

  const url = `https://wttr.in/${encodeURIComponent(state.location)}?format=j1`

  try {
    const res = await fetch(url)
    const json = await res.json()
    return { weatherJson: json }
  } catch {
    return { weatherJson: { error: 'Failed to fetch weather' } }
  }
}
```

---

### üó£ 3.4 Answer Formatter Node (LLM)

```ts
const answerPrompt = ChatPromptTemplate.fromTemplate(`
Convert the JSON weather result into a helpful message.

Location: {location}
Weather JSON: {weatherJson}

Write a short, friendly weather report.
`)

const answerChain = RunnableSequence.from([answerPrompt, model, (out) => out.content.trim()])

async function weatherAnswerNode(state: typeof StateAnnotation.State) {
  console.log('üí¨ Converting weather result to text...')
  const answer = await answerChain.invoke({
    location: state.location,
    weatherJson: JSON.stringify(state.weatherJson),
  })
  return { answer }
}
```

---

## 4Ô∏è‚É£ Final Plug-and-Play File

> üìÑ `graph-weather-tool.ts`

```ts
/**
 * 7.4.2 ‚Äî Graph with Web Tool Node (Weather API)
 */
import { Annotation, StateGraph, START, END } from '@langchain/langgraph'
import { ChatOpenAI } from '@langchain/openai'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { RunnableSequence } from '@langchain/core/runnables'
import fetch from 'node-fetch'
import 'dotenv/config'

/* ---------------------------------- */
/* 1Ô∏è‚É£ State Model */
/* ---------------------------------- */
const StateAnnotation = Annotation.Root({
  input: Annotation<string>(),
  location: Annotation<string>({ reducer: (_, u) => u ?? _ }),
  weatherJson: Annotation<any>({ reducer: (_, u) => u ?? _ }),
  answer: Annotation<string>({ reducer: (_, u) => u ?? _ }),
})

/* ---------------------------------- */
/* 2Ô∏è‚É£ LLM Setup */
/* ---------------------------------- */
const model = new ChatOpenAI({ modelName: 'gpt-4o-mini', temperature: 0 })

/* Extract Location Node (LLM) */
const extractLocationPrompt = ChatPromptTemplate.fromTemplate(`
Extract only the location from the user message:
"{input}"
Return only the location, no extra words.
`)
const extractLocationChain = RunnableSequence.from([extractLocationPrompt, model, (out) => out.content.trim()])

async function extractLocationNode(state: typeof StateAnnotation.State) {
  console.log('üìç Extracting location...')
  const location = await extractLocationChain.invoke({ input: state.input })
  return { location }
}

/* Weather Tool Node (HTTP API) */
async function weatherToolNode(state: typeof StateAnnotation.State) {
  console.log('üå¶ Fetching weather for:', state.location)

  if (!state.location) return { weatherJson: { error: 'No location found' } }

  const url = `https://wttr.in/${encodeURIComponent(state.location)}?format=j1`

  try {
    const res = await fetch(url)
    const json = await res.json()
    return { weatherJson: json }
  } catch {
    return { weatherJson: { error: 'Weather fetch failed' } }
  }
}

/* Answer Node */
const answerPrompt = ChatPromptTemplate.fromTemplate(`
Turn the JSON weather into a helpful, friendly response.

Location: {location}
Weather JSON: {weatherJson}
`)
const answerChain = RunnableSequence.from([answerPrompt, model, (out) => out.content.trim()])

async function weatherAnswerNode(state: typeof StateAnnotation.State) {
  const answer = await answerChain.invoke({
    location: state.location,
    weatherJson: JSON.stringify(state.weatherJson),
  })
  return { answer }
}

/* ---------------------------------- */
/* 3Ô∏è‚É£ Graph Assembly */
/* ---------------------------------- */
const workflow = new StateGraph(StateAnnotation)
  .addNode('extractLocationNode', extractLocationNode)
  .addNode('weatherToolNode', weatherToolNode)
  .addNode('weatherAnswerNode', weatherAnswerNode)
  .addEdge(START, 'extractLocationNode')
  .addEdge('extractLocationNode', 'weatherToolNode')
  .addEdge('weatherToolNode', 'weatherAnswerNode')
  .addEdge('weatherAnswerNode', END)

const app = workflow.compile()

/* ---------------------------------- */
/* 4Ô∏è‚É£ Demo Runner */
/* ---------------------------------- */
async function main() {
  console.log('\nüåç 7.4.2 ‚Äî Weather Tool Graph Demo\n')

  const userQueries = ["What's the weather in Tokyo?", 'Weather at Mumbai', 'Tell me temperature for New York today']

  for (const input of userQueries) {
    console.log(`\nüë§ User: ${input}`)
    const result = await app.invoke({ input })
    console.log('üìç Location:', result.location)
    console.log('üå¶ Weather JSON:', JSON.stringify(result.weatherJson).slice(0, 120) + '...')
    console.log('ü§ñ Final Answer:', result.answer)
  }
}

main().catch(console.error)
```

---

## 5Ô∏è‚É£ Notes & Tips

| Recommended Improvement                | Reason                        |
| -------------------------------------- | ----------------------------- |
| Use `mathjs`/`expr-eval` for safe calc | never eval user input in prod |
| Use a proper weather API + key         | rate limits + accuracy        |
| Add caching                            | weather changes slowly        |
| Add classifier before running tool     | coming in **7.4.3**           |

üî• Pro tip: Turn **`weatherToolNode`** into **batch mode** to call multiple APIs at once ‚Äî perfect for **7.2.4 parallel execution**.

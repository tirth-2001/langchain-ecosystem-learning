# **7.4.3 â€” Decide + Tool (Route to LLM or Web Tool)**

A critical building block of _agentic reasoning_ inside LangGraph.

---

# âœ… **1. Goal â€” Build an AI Router**

We want a graph that:

âœ” Accepts a user query
âœ” Classifies whether the query **requires an external tool**
âœ” Routes to either:

- **LLM Answer Node** (normal chat)
- **Weather Tool Node** (or any tool)
  âœ” Merges the result into a clean final response

This is classical **â€œAgent Tool Selectionâ€** â€” but explicitly controlled in a graph.

Flow:

```
User Input
    â†“
[classifierNode] â†’ "tool" â†’ [toolNode] â†’ [toolAnswerNode]
                â†˜ "llm"  â†’ [llmAnswerNode]
```

---

# ğŸ§  **2. Theory â€” Routing in Graphs**

### **2.1 Why do we need a classifier?**

LLMs hallucinate often.
In free-form agent mode, they may attempt tool calls when not needed.

A **classifier node** enforces:

- predictable routing
- lower cost
- cleaner separation of concerns
- explicit business rules

### **2.2 Types of decisions you can encode**

| Case                                 | Route                |
| ------------------------------------ | -------------------- |
| â€œweatherâ€, â€œtemperatureâ€, â€œforecastâ€ | â†’ weatherToolNode    |
| â€œcalculateâ€, â€œsumâ€, â€œsubtractâ€       | â†’ calculatorToolNode |
| any normal question                  | â†’ llmAnswerNode      |
| ambiguous                            | â†’ llmAnswerNode      |

### **2.3 What LangGraph Feature We Use**

- `addConditionalEdges(fromNode, routerFn, mappingObject)`
- routerFn returns a **string key**
- mappingObject defines **where that key leads**

---

# ğŸ§± **3. Code Snippets (Step-by-Step)**

Below are the small parts first.

---

## **3.1 State Model**

```ts
const StateAnnotation = Annotation.Root({
  input: Annotation<string>(),
  route: Annotation<string>({ reducer: (_, u) => u ?? _ }),
  location: Annotation<string>({ reducer: (_, u) => u ?? _ }),
  weatherJson: Annotation<any>({ reducer: (_, u) => u ?? _ }),
  final: Annotation<string>({ reducer: (_, u) => u ?? _ }),
})
```

---

## **3.2 Classifier Node (LLM-based Routing)**

```ts
const classifyPrompt = ChatPromptTemplate.fromTemplate(`
Classify the user request as one of the following:
- "weather" â†’ if they ask about weather, temperature, rain, climate
- "llm" â†’ all other cases

User input: "{input}"

Return ONLY one word: weather or llm.
`)

const classifyChain = RunnableSequence.from([classifyPrompt, model, (o) => o.content.trim().toLowerCase()])

async function classifierNode(state: typeof StateAnnotation.State) {
  const route = await classifyChain.invoke({ input: state.input })
  console.log('ğŸ” Classifier decided:', route)
  return { route }
}
```

---

## **3.3 Weather Tool Node (Re-using 7.4.2)**

```ts
async function weatherToolNode(state) {
  const url = `https://wttr.in/${encodeURIComponent(state.input)}?format=j1`
  const json = await fetch(url).then((r) => r.json())
  return { weatherJson: json }
}
```

---

## **3.4 Weather Answer Node**

```ts
const weatherAnswerPrompt = ChatPromptTemplate.fromTemplate(`
Location: {input}
Weather JSON: {weatherJson}

Summarize the weather in a friendly 2-sentence message.
`)
const weatherAnsChain = RunnableSequence.from([weatherAnswerPrompt, model, (o) => o.content.trim()])

async function weatherAnswerNode(state) {
  return {
    final: await weatherAnsChain.invoke({
      input: state.input,
      weatherJson: JSON.stringify(state.weatherJson),
    }),
  }
}
```

---

## **3.5 Regular LLM Answer Node (No Tool)**

```ts
const normalChatPrompt = ChatPromptTemplate.fromTemplate(`
Answer the user question conversationally:

User: {input}
`)
const normalChatChain = RunnableSequence.from([normalChatPrompt, model, (o) => o.content.trim()])

async function llmAnswerNode(state) {
  return { final: await normalChatChain.invoke({ input: state.input }) }
}
```

---

# ğŸ§© **4. Final Plug-and-Play Code File**

> ğŸ“„ `graph-decide-tool.ts`

```ts
/**
 * 7.4.3 â€” Decide + Tool Graph
 */

import fetch from 'node-fetch'
import { Annotation, StateGraph, START, END } from '@langchain/langgraph'
import { ChatOpenAI } from '@langchain/openai'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { RunnableSequence } from '@langchain/core/runnables'

/* ---------------------------------- */
/* 1ï¸âƒ£ State */
/* ---------------------------------- */
const StateAnnotation = Annotation.Root({
  input: Annotation<string>(),
  route: Annotation<string>({ reducer: (_, u) => u ?? _ }),
  weatherJson: Annotation<any>({ reducer: (_, u) => u ?? _ }),
  final: Annotation<string>({ reducer: (_, u) => u ?? _ }),
})

/* LLM */
const model = new ChatOpenAI({ modelName: 'gpt-4o-mini', temperature: 0 })

/* ---------------------------------- */
/* 2ï¸âƒ£ Classifier Node */
/* ---------------------------------- */
const classifyPrompt = ChatPromptTemplate.fromTemplate(`
Classify the user request into:
- "weather" â†’ if weather, temperature, climate, rain
- "llm" â†’ anything else
Return only one word.
User input: "{input}"
`)

const classifyChain = RunnableSequence.from([classifyPrompt, model, (o) => o.content.trim().toLowerCase()])

async function classifierNode(state) {
  const route = await classifyChain.invoke({ input: state.input })
  console.log('ğŸ” Classifier:', route)
  return { route }
}

/* ---------------------------------- */
/* 3ï¸âƒ£ Weather Tool Node */
/* ---------------------------------- */
async function weatherToolNode(state) {
  try {
    const url = `https://wttr.in/${encodeURIComponent(state.input)}?format=j1`
    const json = await fetch(url).then((r) => r.json())
    return { weatherJson: json }
  } catch {
    return { weatherJson: { error: 'fetch failed' } }
  }
}

/* Weather â†’ Answer  */
const weatherAnswerPrompt = ChatPromptTemplate.fromTemplate(`
Location: {input}
Weather JSON: {weatherJson}
Write a short, friendly weather summary.
`)
const weatherAnsChain = RunnableSequence.from([weatherAnswerPrompt, model, (o) => o.content.trim()])

async function weatherAnswerNode(state) {
  return {
    final: await weatherAnsChain.invoke({
      input: state.input,
      weatherJson: JSON.stringify(state.weatherJson),
    }),
  }
}

/* ---------------------------------- */
/* 4ï¸âƒ£ Normal LLM Answer Node */
/* ---------------------------------- */
const normalChatPrompt = ChatPromptTemplate.fromTemplate(`
Respond conversationally:

User: {input}
`)
const normalChatChain = RunnableSequence.from([normalChatPrompt, model, (o) => o.content.trim()])

async function llmAnswerNode(state) {
  return { final: await normalChatChain.invoke({ input: state.input }) }
}

/* ---------------------------------- */
/* 5ï¸âƒ£ Build Graph */
/* ---------------------------------- */
const workflow = new StateGraph(StateAnnotation)
  .addNode('classifierNode', classifierNode)
  .addNode('weatherToolNode', weatherToolNode)
  .addNode('weatherAnswerNode', weatherAnswerNode)
  .addNode('llmAnswerNode', llmAnswerNode)
  .addEdge(START, 'classifierNode')
  .addConditionalEdges('classifierNode', (state) => state.route, {
    weather: 'weatherToolNode',
    llm: 'llmAnswerNode',
  })
  .addEdge('weatherToolNode', 'weatherAnswerNode')
  .addEdge('weatherAnswerNode', END)
  .addEdge('llmAnswerNode', END)

const app = workflow.compile()

/* ---------------------------------- */
/* 6ï¸âƒ£ Demo */
/* ---------------------------------- */
async function main() {
  const tests = ['Whatâ€™s the weather in Paris?', 'Tell me a joke', 'Temperature for Mumbai']

  for (const input of tests) {
    console.log('\n=====================')
    console.log('ğŸ‘¤ User:', input)
    const r = await app.invoke({ input })
    console.log('ğŸ¤– Final:', r.final)
  }
}

main().catch(console.error)
```

---

# ğŸ“ **5. Notes & Tips**

### âœ” Strong Pattern for Real Systems

This is identical to how:

- OpenAI GPT-4 Agents
- ReAct agents
- AutoGPT branches
- CrewAI task routers

decide **when** to call tools.

### âœ” You can expand routing

Add more routes:

- `"calculator"`
- `"web_search"`
- `"rag"`
- `"code_exec"`
- `"ecommerce"`

### âœ” Router is not just LLM-based

You can encode rules:

```ts
if (input.includes('price')) return 'product_tool'
```

### âœ” Next Stage (7.4.4)

We'll mix:

- **Tool**
- **HITL**
- **Routing**
- **LLM**

into one coherent workflow.

This is where LangGraph really shines.
